{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjectDir = str('/media/corey/4TB-WDBlue/data-thesis/DTI/merged_data/')\n",
    "DirExtName = str('/4o/averageFAs/')\n",
    "FA_filenames = np.loadtxt('/media/corey/4TB-WDBlue/data-thesis/DTI/FA_fileList.txt',dtype=str)\n",
    "#Load subjectlist of interest, store IDs as integers\n",
    "sub_list = np.loadtxt('/home/corey/thesis-EP/EP_scripts/diagnostics/Logs/GoodSubs_28April23.txt',dtype=str)\n",
    "#Store subject names as a list with a standard suffix if provided\n",
    "sub_names = sub_list\n",
    "\n",
    "subjectInfo = pd.read_csv(open('/media/corey/4TB-WDBlue/data-thesis/subject_info.csv'),delim_whitespace=True,usecols=(4,11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "control_FA = []\n",
    "nonaff_FA = []\n",
    "aff_FA = []\n",
    "n_control = 0\n",
    "n_aff = 0\n",
    "n_nonaff = 0\n",
    "for n in sub_names:\n",
    "    path_to_data = subjectDir + n + DirExtName\n",
    "    phen = subjectInfo.loc[subjectInfo['src_subject_id'] == n]\n",
    "    pdesc = phen['phenotype_description'].values[0]\n",
    "    for r in FA_filenames:\n",
    "        fa_filename = path_to_data + r\n",
    "        fa_file = nib.load(fa_filename)\n",
    "        fa_data = fa_file.get_fdata()\n",
    "        FA_val = np.max(fa_data)\n",
    "        if pdesc == 'In,good,health':\n",
    "            control_FA.append([FA_val, r])\n",
    "        if pdesc == 'Non-affective,psychosis':\n",
    "            nonaff_FA.append([FA_val, r])\n",
    "        if pdesc == 'Affective,psychosis':\n",
    "            aff_FA.append([FA_val, r])\n",
    "    if pdesc == 'In,good,health':\n",
    "        n_control += 1\n",
    "    if pdesc == 'Non-affective,psychosis':\n",
    "        n_nonaff +=1\n",
    "    if pdesc == 'Affective,psychosis':\n",
    "        n_aff += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_regionwise_struct = []\n",
    "n_rw_struct = []\n",
    "a_rw_struct = []\n",
    "\n",
    "all_FAs_c = []\n",
    "mean_FAs_c = []\n",
    "stdv_FA_c = []\n",
    "\n",
    "all_FAs_n = []\n",
    "mean_FAs_n = []\n",
    "stdv_FA_n = []\n",
    "\n",
    "all_FAs_a = []\n",
    "mean_FAs_a = []\n",
    "stdv_FA_a = []\n",
    "\n",
    "curr_region = 0\n",
    "for r in FA_filenames:\n",
    "    regional_c = [tuple for tuple in control_FA if any(r == i for i in tuple)] #Sort data by region\n",
    "    reg_n = [tuple for tuple in nonaff_FA if any(r == i for i in tuple)]\n",
    "    reg_a = [tuple for tuple in aff_FA if any(r == i for i in tuple)]\n",
    "\n",
    "    c_regionwise_struct.append(regional_c) #Create list of tuples for each group\n",
    "    n_rw_struct.append(reg_n)\n",
    "    a_rw_struct.append(reg_a)\n",
    "\n",
    "    fullc = [list(zip(*c_regionwise_struct[curr_region]))[0],r]\n",
    "    meanc = [np.mean(list(zip(*c_regionwise_struct[curr_region]))[0]),r]\n",
    "    stdvc = [np.std(list(zip(*c_regionwise_struct[curr_region]))[0]),r]\n",
    "    fulln = [list(zip(*n_rw_struct[curr_region]))[0],r]\n",
    "    meann = [np.mean(list(zip(*n_rw_struct[curr_region]))[0]),r]\n",
    "    stdvn = [np.std(list(zip(*n_rw_struct[curr_region]))[0]),r]\n",
    "    fulla = [list(zip(*a_rw_struct[curr_region]))[0],r]\n",
    "    meana = [np.mean(list(zip(*a_rw_struct[curr_region]))[0]),r]\n",
    "    stdva = [np.std(list(zip(*a_rw_struct[curr_region]))[0]),r]\n",
    "\n",
    "    all_FAs_c.append(fullc) #Store all, mean, and standard deviation values in list including region labels\n",
    "    mean_FAs_c.append(meanc)\n",
    "    stdv_FA_c.append(stdvc)\n",
    "\n",
    "    all_FAs_n.append(fulln)\n",
    "    mean_FAs_n.append(meann)\n",
    "    stdv_FA_n.append(stdvn)\n",
    "\n",
    "    all_FAs_a.append(fulla)\n",
    "    mean_FAs_a.append(meana)\n",
    "    stdv_FA_a.append(stdva)\n",
    "\n",
    "    curr_region += 1 #Increase index counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mean_FAs_c)\n",
    "print(mean_FAs_n)\n",
    "print(mean_FAs_a)\n",
    "print(stdv_FA_c)\n",
    "print(stdv_FA_n)\n",
    "print(stdv_FA_a)\n",
    "print(n_control, n_nonaff, n_aff)\n",
    "#Plot histograms of average FA for each tract for each group (visually inspect if normally distributed) for groups of size n < 30, peform \n",
    "#Shapiro-Wilk test for normality\n",
    "curr_region = 0\n",
    "f,ax = plt.subplots(31,3)\n",
    "#Overall plot (should be reduced into individual rows for readability) - axes should be trimmed, colors per tract should be implemented\n",
    "for x in enumerate(FA_filenames):\n",
    "    h, bins, _ = ax[x[0],0].hist(all_FAs_c[x[0]][0],label=x[1])\n",
    "    h, bins, _ = ax[x[0],1].hist(all_FAs_n[x[0]][0],label=x[1])\n",
    "    h, bins, _ = ax[x[0],2].hist(all_FAs_a[x[0]][0],label=x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.5126211537281113, 0.014290499847178317, 'jhu_13.nii'], [2.1556091371931463, 0.03455396500308766, 'jhu_8.nii'], [2.089582576751846, 0.04029085965101451, 'thal_1.nii']]\n",
      "[]\n",
      "[]\n",
      "[[2.540673947064671, 0.01345914020745331, 'jhu_13.nii'], [2.2269868960553536, 0.029252868620822985, 'jhu_8.nii'], [2.0862100345305903, 0.041032122047747914, 'thal_1.nii']]\n",
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "#Calculate mean and standard deviation for the FA values in each group and perform subsequent T-tests for differences in means with heterogenous variance\n",
    "import scipy.stats as stats\n",
    "Difference_C_N = []\n",
    "Difference_C_A = []\n",
    "Difference_N_A = []\n",
    "difference_c_n_fs = []\n",
    "difference_c_a_fs = []\n",
    "difference_n_a_fs = []\n",
    "x = enumerate(FA_filenames)\n",
    "\n",
    "for r in x:\n",
    "    test_c_n = stats.ttest_ind(all_FAs_c[r[0]][0],all_FAs_n[r[0]][0],equal_var=False)\n",
    "    if test_c_n[1] <= 0.05:\n",
    "        store_c_n = [test_c_n[0], test_c_n[1], r[1]]\n",
    "        Difference_C_N.append(store_c_n)\n",
    "    test_c_a = stats.ttest_ind(all_FAs_c[r[0]][0],all_FAs_a[r[0]][0],equal_var=False)\n",
    "    if test_c_a[1] <= 0.05:\n",
    "        store_c_a = [test_c_a[0], test_c_a[1], r[1]]\n",
    "        Difference_C_A.append(store_c_a)\n",
    "    test_n_a = stats.ttest_ind(all_FAs_n[r[0]][0],all_FAs_a[r[0]][0],equal_var=False)\n",
    "    if test_n_a[1] <= 0.05:\n",
    "        store_n_a = [test_n_a[0], test_n_a[1], r[1]]\n",
    "        Difference_N_A.append(store_n_a)\n",
    "\n",
    "    test_fs_c_n = stats.ttest_ind_from_stats(mean1=mean_FAs_c[r[0]][0],mean2=mean_FAs_n[r[0]][0],std1=stdv_FA_c[r[0]][0],std2=stdv_FA_n[r[0]][0],nobs1=n_control,nobs2=n_nonaff)\n",
    "    if test_fs_c_n[1] <= 0.05:\n",
    "        store_fs_c_n = [test_fs_c_n[0], test_fs_c_n[1], r[1]]\n",
    "        difference_c_n_fs.append(store_fs_c_n)\n",
    "    test_fs_c_a = stats.ttest_ind_from_stats(mean1=mean_FAs_c[r[0]][0],mean2=mean_FAs_a[r[0]][0],std1=stdv_FA_c[r[0]][0],std2=stdv_FA_a[r[0]][0],nobs1=n_control,nobs2=n_aff)\n",
    "    if test_fs_c_a[1] <= 0.05:\n",
    "        store_fs_c_a = [test_fs_c_a[0], test_fs_c_a[1], r[1]]\n",
    "        difference_c_a_fs.append(store_fs_c_a)\n",
    "    test_fs_n_a = stats.ttest_ind_from_stats(mean1=mean_FAs_n[r[0]][0],mean2=mean_FAs_a[r[0]][0],std1=stdv_FA_n[r[0]][0],std2=stdv_FA_a[r[0]][0],nobs1=n_nonaff,nobs2=n_aff)\n",
    "    if test_fs_n_a[1] <= 0.05:\n",
    "        store_fs_n_a = [test_fs_n_a[0], test_fs_n_a[1], r[1]]\n",
    "        difference_n_a_fs.append(store_fs_n_a)\n",
    "#Store significant results in lists\n",
    "print(difference_c_n_fs)\n",
    "print(difference_c_a_fs)\n",
    "print(difference_n_a_fs)\n",
    "print(Difference_C_N)\n",
    "print(Difference_C_A)\n",
    "print(Difference_N_A)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "diff_med_c_n = []\n",
    "x = enumerate(FA_filenames)\n",
    "for r in x:\n",
    "    med_test_c_n = stats.median_test(all_FAs_c[r[0]][0],all_FAs_n[r[0]][0])\n",
    "    if med_test_c_n[1] <= 0.05:\n",
    "        store_med_c_n = (med_test_c_n[0], med_test_c_n[1], r[1])\n",
    "        diff_med_c_n.append(store_med_c_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bonferroni correction and store in new table\n",
    "\n",
    "#Results would not survive bonferroni correction for 31 tests\n",
    "\n",
    "#Correct for multiple tests by estimating proportion of truly null tests\n",
    "#Assess skewness of distribution of p-values\n",
    "\n",
    "#Store p-values and plot distribution, quantify how much it deviates\n",
    "#From the uniform distribution (see UW lecuture 10 and various web sources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "cFA = []\n",
    "pFA = []\n",
    "n_c = 0\n",
    "n_p = 0\n",
    "for n in sub_names:\n",
    "    path_to_data = subjectDir + n + DirExtName\n",
    "    phen = subjectInfo.loc[subjectInfo['src_subject_id'] == n]\n",
    "    pdesc = phen['phenotype_description'].values[0]\n",
    "    for r in FA_filenames:\n",
    "        fa_filename = path_to_data + r\n",
    "        fa_file = nib.load(fa_filename)\n",
    "        fa_data = fa_file.get_fdata()\n",
    "        FA_val = np.max(fa_data)\n",
    "        if pdesc == 'In,good,health':\n",
    "            cFA.append([FA_val, r])\n",
    "        if pdesc == 'Non-affective,psychosis' or pdesc=='Affective,psychosis':\n",
    "            pFA.append([FA_val, r])\n",
    "\n",
    "    if pdesc == 'In,good,health':\n",
    "        n_c += 1\n",
    "    if pdesc == 'Non-affective,psychosis' or pdesc=='Affective,psychosis':\n",
    "        n_p +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_rw = []\n",
    "p_rw = []\n",
    "\n",
    "c_all = []\n",
    "m_c = []\n",
    "st_c = []\n",
    "\n",
    "p_all = []\n",
    "m_p = []\n",
    "st_p = []\n",
    "curr_region = 0 #Alternatively could use enumerate\n",
    "for r in FA_filenames:\n",
    "    r_c = [tuple for tuple in cFA if any(r == i for i in tuple)] #Sort data by region\n",
    "    r_p = [tuple for tuple in pFA if any(r == i for i in tuple)]\n",
    "    c_rw.append(r_c) #Create list of tuples for each group\n",
    "    p_rw.append(r_p)\n",
    "\n",
    "    fc = [list(zip(*c_rw[curr_region]))[0],r]\n",
    "    av_c = [np.mean(list(zip(*c_rw[curr_region]))[0]),r]\n",
    "    std_c = [np.std(list(zip(*c_rw[curr_region]))[0]),r]\n",
    "    \n",
    "    fp = [list(zip(*p_rw[curr_region]))[0],r]\n",
    "    av_p = [np.mean(list(zip(*p_rw[curr_region]))[0]),r]\n",
    "    std_p = [np.std(list(zip(*p_rw[curr_region]))[0]),r]\n",
    "\n",
    "    c_all.append(fc) #Store all, mean, and standard deviation values in list including region labels\n",
    "    m_c.append(av_c)\n",
    "    st_c.append(std_c)\n",
    "\n",
    "    p_all.append(fp)\n",
    "    m_p.append(av_p)\n",
    "    st_p.append(std_p)\n",
    "    curr_region += 1 #Increase index counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ttest_indResult(statistic=0.5901287924446175, pvalue=0.5574120901347083)\n",
      "Ttest_indResult(statistic=0.3121695547902057, pvalue=0.7558515189896082)\n",
      "Ttest_indResult(statistic=0.13757893112120492, pvalue=0.8910377938018577)\n",
      "Ttest_indResult(statistic=0.7145358510606727, pvalue=0.4779512493400675)\n",
      "Ttest_indResult(statistic=1.4970705456086917, pvalue=0.1385698847103799)\n",
      "Ttest_indResult(statistic=0.49987291406894135, pvalue=0.6188353722094246)\n",
      "Ttest_indResult(statistic=1.5352670450346528, pvalue=0.1301378204074506)\n",
      "Ttest_indResult(statistic=2.2883576406285537, pvalue=0.025433207612265817)\n",
      "Ttest_indResult(statistic=0.9842461929951208, pvalue=0.328487807122139)\n",
      "Ttest_indResult(statistic=1.8316568255949144, pvalue=0.0708483322423259)\n",
      "Ttest_indResult(statistic=1.2534458992246207, pvalue=0.21383029095247444)\n",
      "Ttest_indResult(statistic=1.5044563425298816, pvalue=0.13718496564585947)\n",
      "Ttest_indResult(statistic=0.5386972324507683, pvalue=0.591972134912673)\n",
      "Ttest_indResult(statistic=1.0985106673755807, pvalue=0.2765124504973761)\n",
      "Ttest_indResult(statistic=1.7215898508451357, pvalue=0.08933183546795835)\n",
      "Ttest_indResult(statistic=0.13972960996976058, pvalue=0.8893428667467107)\n",
      "Ttest_indResult(statistic=1.6261303342259956, pvalue=0.10827652258679699)\n",
      "Ttest_indResult(statistic=1.2570020974977267, pvalue=0.21268633065373707)\n",
      "Ttest_indResult(statistic=0.7729707520602728, pvalue=0.44190521199315)\n",
      "Ttest_indResult(statistic=0.6977994694541001, pvalue=0.4879776159520903)\n",
      "Ttest_indResult(statistic=1.1836741870945635, pvalue=0.2405620625883548)\n",
      "Ttest_indResult(statistic=1.3114296118178652, pvalue=0.19413171997648382)\n",
      "Ttest_indResult(statistic=2.2543022434195197, pvalue=0.027267605822903853)\n",
      "Ttest_indResult(statistic=0.6116417486235122, pvalue=0.5429749244001825)\n",
      "Ttest_indResult(statistic=1.6864924662249814, pvalue=0.09677335667575204)\n",
      "Ttest_indResult(statistic=1.247050885523737, pvalue=0.21696690734896812)\n",
      "Ttest_indResult(statistic=1.278830881415049, pvalue=0.20723340123551864)\n",
      "Ttest_indResult(statistic=1.433946821307489, pvalue=0.15623462136283717)\n",
      "Ttest_indResult(statistic=1.4303674632095167, pvalue=0.15722401613792525)\n",
      "Ttest_indResult(statistic=0.9673337149198938, pvalue=0.3376496600006339)\n",
      "Ttest_indResult(statistic=0.9716675251503809, pvalue=0.33514781468905186)\n",
      "[[2.2883576406285537, 0.025433207612265817, 'jhu_13.nii'], [2.2543022434195197, 0.027267605822903853, 'jhu_8.nii']]\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "DelCP = []\n",
    "x = enumerate(FA_filenames)\n",
    "for r in x:\n",
    "    test_c_p = stats.ttest_ind(c_all[r[0]][0],p_all[r[0]][0],equal_var=False)\n",
    "    if test_c_p[1] <= 0.05:\n",
    "        store_c_p = [test_c_p[0], test_c_p[1], r[1]]\n",
    "        DelCP.append(store_c_p)\n",
    "#Store significant results in lists\n",
    "print(DelCP)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
